{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292f703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcce7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load IMDB dataset\n",
    "df = pd.read_csv(\"../../data/raw/IMDB Dataset.csv\")\n",
    "\n",
    "# Check structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1bd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment labels: positive -> 1, negative -> 0\n",
    "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['review'].values, df['label'].values, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d57404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\.conda\\envs\\tf-gpu\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use DeBERTa-v3-small for speed and performance balance\n",
    "\n",
    "model_name = \"microsoft/deberta-v3-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Tokenize data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=256)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41177438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a1a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.41.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "print(model.config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5bc9df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force CPU usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb9e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\.conda\\envs\\tf-gpu\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Further reduce batch size and enable gradient accumulation to avoid OOM\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deberta-imdb-checkpoints\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=True, \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=3\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108e7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3835ba26f024572b47e92f589521955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7827, 'grad_norm': 0.07908125966787338, 'learning_rate': 4.952857142857143e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6052, 'grad_norm': 58.32316207885742, 'learning_rate': 4.905238095238095e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6208, 'grad_norm': 138.674072265625, 'learning_rate': 4.857619047619048e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6335, 'grad_norm': 0.17224936187267303, 'learning_rate': 4.8100952380952385e-05, 'epoch': 0.11}\n",
      "{'loss': 0.5046, 'grad_norm': 0.05213278904557228, 'learning_rate': 4.762476190476191e-05, 'epoch': 0.14}\n",
      "{'loss': 0.5645, 'grad_norm': 0.1248655915260315, 'learning_rate': 4.714857142857143e-05, 'epoch': 0.17}\n",
      "{'loss': 0.5568, 'grad_norm': 36.40721893310547, 'learning_rate': 4.667238095238096e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5298, 'grad_norm': 135.52699279785156, 'learning_rate': 4.6196190476190474e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6405, 'grad_norm': 0.11017625778913498, 'learning_rate': 4.5721904761904765e-05, 'epoch': 0.26}\n",
      "{'loss': 0.5564, 'grad_norm': 0.17866413295269012, 'learning_rate': 4.524571428571429e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5405, 'grad_norm': 0.10362128168344498, 'learning_rate': 4.476952380952381e-05, 'epoch': 0.31}\n",
      "{'loss': 0.5335, 'grad_norm': 0.10341700911521912, 'learning_rate': 4.429333333333334e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6164, 'grad_norm': 43.786041259765625, 'learning_rate': 4.3817142857142854e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4576, 'grad_norm': 0.0845937505364418, 'learning_rate': 4.3341904761904764e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4383, 'grad_norm': 3.8245162963867188, 'learning_rate': 4.2865714285714286e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5195, 'grad_norm': 0.06056242436170578, 'learning_rate': 4.2389523809523815e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4892, 'grad_norm': 52.55998611450195, 'learning_rate': 4.191333333333334e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4154, 'grad_norm': 0.16404548287391663, 'learning_rate': 4.143714285714286e-05, 'epoch': 0.51}\n",
      "{'loss': 0.5154, 'grad_norm': 0.24358634650707245, 'learning_rate': 4.096095238095238e-05, 'epoch': 0.54}\n",
      "{'loss': 0.5024, 'grad_norm': 0.11287657916545868, 'learning_rate': 4.048476190476191e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4912, 'grad_norm': 0.7103670239448547, 'learning_rate': 4.0008571428571426e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5416, 'grad_norm': 0.2864256501197815, 'learning_rate': 3.9533333333333337e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4971, 'grad_norm': 0.3658166825771332, 'learning_rate': 3.905714285714286e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5044, 'grad_norm': 0.05145393684506416, 'learning_rate': 3.858190476190476e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4826, 'grad_norm': 0.12034428119659424, 'learning_rate': 3.810571428571429e-05, 'epoch': 0.71}\n",
      "{'loss': 0.5152, 'grad_norm': 0.10648605972528458, 'learning_rate': 3.762952380952381e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4651, 'grad_norm': 0.28910937905311584, 'learning_rate': 3.7153333333333336e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4534, 'grad_norm': 0.037664689123630524, 'learning_rate': 3.667714285714286e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4486, 'grad_norm': 37.09074783325195, 'learning_rate': 3.620095238095239e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4356, 'grad_norm': 0.5511536598205566, 'learning_rate': 3.57247619047619e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4474, 'grad_norm': 18.917072296142578, 'learning_rate': 3.524857142857143e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4461, 'grad_norm': 26.306488037109375, 'learning_rate': 3.4773333333333335e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4549, 'grad_norm': 0.4089871942996979, 'learning_rate': 3.4297142857142864e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3708, 'grad_norm': 0.015126009471714497, 'learning_rate': 3.382095238095238e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4184, 'grad_norm': 55.72637939453125, 'learning_rate': 3.334476190476191e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abae6bfd0bf543b8a5ba3757dc4c4a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5072982311248779, 'eval_runtime': 270.2299, 'eval_samples_per_second': 55.508, 'eval_steps_per_second': 55.508, 'epoch': 1.0}\n",
      "{'loss': 0.3003, 'grad_norm': 0.010231323540210724, 'learning_rate': 3.286857142857143e-05, 'epoch': 1.03}\n",
      "{'loss': 0.2797, 'grad_norm': 0.032950349152088165, 'learning_rate': 3.239238095238095e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3434, 'grad_norm': 0.018723268061876297, 'learning_rate': 3.1918095238095244e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3368, 'grad_norm': 0.020533226430416107, 'learning_rate': 3.144190476190476e-05, 'epoch': 1.11}\n",
      "{'loss': 0.355, 'grad_norm': 0.2256549596786499, 'learning_rate': 3.096571428571429e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3695, 'grad_norm': 0.5653647780418396, 'learning_rate': 3.048952380952381e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2713, 'grad_norm': 0.025481009855866432, 'learning_rate': 3.0013333333333333e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2737, 'grad_norm': 0.06420562416315079, 'learning_rate': 2.9538095238095236e-05, 'epoch': 1.23}\n",
      "{'loss': 0.2849, 'grad_norm': 0.2877642512321472, 'learning_rate': 2.9061904761904762e-05, 'epoch': 1.26}\n",
      "{'loss': 0.3137, 'grad_norm': 0.02397259697318077, 'learning_rate': 2.8585714285714287e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3474, 'grad_norm': 0.03957372158765793, 'learning_rate': 2.8109523809523813e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3371, 'grad_norm': 0.12305673211812973, 'learning_rate': 2.7633333333333332e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3077, 'grad_norm': 0.039331112056970596, 'learning_rate': 2.7157142857142858e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3286, 'grad_norm': 214.27053833007812, 'learning_rate': 2.6680952380952383e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3189, 'grad_norm': 1.6483200788497925, 'learning_rate': 2.6204761904761905e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2835, 'grad_norm': 18.109670639038086, 'learning_rate': 2.572857142857143e-05, 'epoch': 1.46}\n",
      "{'loss': 0.2693, 'grad_norm': 0.008584391325712204, 'learning_rate': 2.5253333333333334e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2829, 'grad_norm': 0.007437983527779579, 'learning_rate': 2.4778095238095238e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3339, 'grad_norm': 26.770305633544922, 'learning_rate': 2.4301904761904763e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3046, 'grad_norm': 17.977588653564453, 'learning_rate': 2.382571428571429e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2819, 'grad_norm': 0.028679819777607918, 'learning_rate': 2.334952380952381e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2723, 'grad_norm': 0.007259998004883528, 'learning_rate': 2.2873333333333337e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2946, 'grad_norm': 0.17472700774669647, 'learning_rate': 2.239809523809524e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3569, 'grad_norm': 3.060518503189087, 'learning_rate': 2.1921904761904762e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2413, 'grad_norm': 460.4677429199219, 'learning_rate': 2.1445714285714285e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2711, 'grad_norm': 21.36884117126465, 'learning_rate': 2.096952380952381e-05, 'epoch': 1.74}\n",
      "{'loss': 0.2988, 'grad_norm': 1.7204264402389526, 'learning_rate': 2.0493333333333333e-05, 'epoch': 1.77}\n",
      "{'loss': 0.2724, 'grad_norm': 0.047795992344617844, 'learning_rate': 2.001904761904762e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3176, 'grad_norm': 0.08808033168315887, 'learning_rate': 1.9542857142857143e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2642, 'grad_norm': 21.53167152404785, 'learning_rate': 1.9066666666666668e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3006, 'grad_norm': 0.2410474419593811, 'learning_rate': 1.859047619047619e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2392, 'grad_norm': 0.036659203469753265, 'learning_rate': 1.8114285714285713e-05, 'epoch': 1.91}\n",
      "{'loss': 0.2988, 'grad_norm': 0.03587593883275986, 'learning_rate': 1.7638095238095238e-05, 'epoch': 1.94}\n",
      "{'loss': 0.2589, 'grad_norm': 0.05573268234729767, 'learning_rate': 1.7162857142857145e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2726, 'grad_norm': 0.015249514020979404, 'learning_rate': 1.6686666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df07f67e1f4490acd90a0e6be429cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4727267622947693, 'eval_runtime': 293.7466, 'eval_samples_per_second': 51.064, 'eval_steps_per_second': 51.064, 'epoch': 2.0}\n",
      "{'loss': 0.1931, 'grad_norm': 27.44675636291504, 'learning_rate': 1.6210476190476193e-05, 'epoch': 2.03}\n",
      "{'loss': 0.1501, 'grad_norm': 0.03052656538784504, 'learning_rate': 1.5734285714285715e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1611, 'grad_norm': 0.00967489741742611, 'learning_rate': 1.5258095238095237e-05, 'epoch': 2.09}\n",
      "{'loss': 0.1605, 'grad_norm': 0.04285068437457085, 'learning_rate': 1.4781904761904763e-05, 'epoch': 2.11}\n",
      "{'loss': 0.1667, 'grad_norm': 0.005992744117975235, 'learning_rate': 1.4305714285714287e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1651, 'grad_norm': 0.04180140793323517, 'learning_rate': 1.382952380952381e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1549, 'grad_norm': 0.025427747517824173, 'learning_rate': 1.3353333333333335e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1314, 'grad_norm': 0.00918477401137352, 'learning_rate': 1.2877142857142857e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1502, 'grad_norm': 0.009326145052909851, 'learning_rate': 1.2400952380952381e-05, 'epoch': 2.26}\n",
      "{'loss': 0.189, 'grad_norm': 0.012724648229777813, 'learning_rate': 1.1924761904761905e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1657, 'grad_norm': 0.009265884757041931, 'learning_rate': 1.1448571428571429e-05, 'epoch': 2.31}\n",
      "{'loss': 0.1984, 'grad_norm': 1.1453287601470947, 'learning_rate': 1.0973333333333334e-05, 'epoch': 2.34}\n",
      "{'loss': 0.1057, 'grad_norm': 0.03474591672420502, 'learning_rate': 1.0497142857142858e-05, 'epoch': 2.37}\n",
      "{'loss': 0.1635, 'grad_norm': 0.014604935422539711, 'learning_rate': 1.0021904761904763e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1493, 'grad_norm': 0.013146080076694489, 'learning_rate': 9.546666666666668e-06, 'epoch': 2.43}\n",
      "{'loss': 0.1566, 'grad_norm': 0.017177321016788483, 'learning_rate': 9.07047619047619e-06, 'epoch': 2.46}\n",
      "{'loss': 0.148, 'grad_norm': 0.024763504043221474, 'learning_rate': 8.594285714285714e-06, 'epoch': 2.49}\n",
      "{'loss': 0.1525, 'grad_norm': 17.336828231811523, 'learning_rate': 8.118095238095238e-06, 'epoch': 2.51}\n",
      "{'loss': 0.1419, 'grad_norm': 0.008812649175524712, 'learning_rate': 7.641904761904762e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1634, 'grad_norm': 0.079173743724823, 'learning_rate': 7.165714285714287e-06, 'epoch': 2.57}\n",
      "{'loss': 0.1918, 'grad_norm': 0.028557417914271355, 'learning_rate': 6.690476190476192e-06, 'epoch': 2.6}\n",
      "{'loss': 0.1418, 'grad_norm': 0.008531089872121811, 'learning_rate': 6.214285714285715e-06, 'epoch': 2.63}\n",
      "{'loss': 0.1511, 'grad_norm': 0.01412810105830431, 'learning_rate': 5.738095238095238e-06, 'epoch': 2.66}\n",
      "{'loss': 0.1128, 'grad_norm': 0.012501229532063007, 'learning_rate': 5.261904761904763e-06, 'epoch': 2.69}\n",
      "{'loss': 0.2149, 'grad_norm': 0.014220641925930977, 'learning_rate': 4.785714285714286e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1404, 'grad_norm': 0.04429025948047638, 'learning_rate': 4.30952380952381e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1698, 'grad_norm': 38.226287841796875, 'learning_rate': 3.833333333333334e-06, 'epoch': 2.77}\n",
      "{'loss': 0.1142, 'grad_norm': 0.010745981708168983, 'learning_rate': 3.357142857142857e-06, 'epoch': 2.8}\n",
      "{'loss': 0.1597, 'grad_norm': 0.012074217200279236, 'learning_rate': 2.880952380952381e-06, 'epoch': 2.83}\n",
      "{'loss': 0.1361, 'grad_norm': 0.017242485657334328, 'learning_rate': 2.404761904761905e-06, 'epoch': 2.86}\n",
      "{'loss': 0.152, 'grad_norm': 0.1536540985107422, 'learning_rate': 1.9285714285714285e-06, 'epoch': 2.89}\n",
      "{'loss': 0.1509, 'grad_norm': 0.03206504508852959, 'learning_rate': 1.4533333333333335e-06, 'epoch': 2.91}\n",
      "{'loss': 0.1432, 'grad_norm': 0.08510534465312958, 'learning_rate': 9.771428571428573e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1138, 'grad_norm': 945.2777099609375, 'learning_rate': 5.01904761904762e-07, 'epoch': 2.97}\n",
      "{'loss': 0.1535, 'grad_norm': 0.00468537537381053, 'learning_rate': 2.5714285714285715e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0fd8fdbdcd4a8ab8cc9cfde58c0cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48863184452056885, 'eval_runtime': 263.6066, 'eval_samples_per_second': 56.903, 'eval_steps_per_second': 56.903, 'epoch': 3.0}\n",
      "{'train_runtime': 15669.2219, 'train_samples_per_second': 6.701, 'train_steps_per_second': 3.351, 'train_loss': 0.3227773905436198, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd7c3b3f0494942a4a5e92907278658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.93      0.92      7411\n",
      "    Positive       0.93      0.90      0.92      7589\n",
      "\n",
      "    accuracy                           0.92     15000\n",
      "   macro avg       0.92      0.92      0.92     15000\n",
      "weighted avg       0.92      0.92      0.92     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(val_labels, preds))\n",
    "print(classification_report(val_labels, preds, target_names=[\"Negative\", \"Positive\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
